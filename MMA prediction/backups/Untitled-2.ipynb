{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "# CREATING FUNCTION to get each fight urls from a fighter's URL\n",
    "def get_fighter_fight_urls(fighter_url):\n",
    "    page = requests.get(fighter_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    fight_urls = []\n",
    "    \n",
    "    fight_rows = soup.find_all('tr', class_='b-fight-details__table-row')\n",
    "    for fight_row in fight_rows:\n",
    "        onclick_value = fight_row.get('onclick')\n",
    "        if onclick_value:\n",
    "            match = re.search(r\"'(http://www.ufcstats.com/fight-details/.+?)'\", onclick_value)\n",
    "            if match:\n",
    "                fight_link = match.group(1)\n",
    "                fight_urls.append(fight_link)\n",
    "    \n",
    "    return fight_urls\n",
    "\n",
    "\n",
    "#Scrape fighter statistics\n",
    "import datetime\n",
    "def get_numeric_value(value_str):\n",
    "    try:\n",
    "        return float(value_str)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def convert_height(height_str):\n",
    "    height_str = height_str.replace('\"', '')\n",
    "    feet, inches = map(int, height_str.split(\"'\"))\n",
    "    total_inches = feet * 12 + inches\n",
    "    return total_inches\n",
    "\n",
    "def convert_weight(weight_str):\n",
    "    return float(weight_str.replace('lbs.', '').strip())\n",
    "\n",
    "def convert_reach(reach_str):\n",
    "    if reach_str == '--':\n",
    "        return None\n",
    "    return float(reach_str.replace('\"', '').strip())\n",
    "\n",
    "def convert_percentage(percentage_str):\n",
    "    try:\n",
    "        if isinstance(percentage_str, str):\n",
    "            numeric_value = float(percentage_str.replace('%', '')) / 100\n",
    "            return numeric_value\n",
    "        elif isinstance(percentage_str, float):\n",
    "            return percentage_str  # Already a float, no conversion needed\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def fighter_stats(fighter_url):\n",
    "    fighter_page = requests.get(fighter_url)\n",
    "    fighter_soup = BeautifulSoup(fighter_page.content, 'html.parser')\n",
    "\n",
    "    fighter_data = {}\n",
    "    fighter_physical_stats = fighter_soup.find('div', class_='b-list__info-box')\n",
    "    if fighter_physical_stats:\n",
    "        physical_details = fighter_physical_stats.find_all('li', class_='b-list__box-list-item')\n",
    "        for detail in physical_details:\n",
    "            label = detail.find('i', class_='b-list__box-item-title').get_text(strip=True)\n",
    "            value = detail.get_text(strip=True).replace(label, '').strip()\n",
    "\n",
    "            if label == 'Height:':\n",
    "                fighter_data[label] = convert_height(value)\n",
    "            elif label == 'Weight:':\n",
    "                fighter_data[label] = convert_weight(value)\n",
    "            elif label == 'Reach:':\n",
    "                fighter_data[label] = convert_reach(value)\n",
    "            else:\n",
    "                fighter_data[label] = value\n",
    "\n",
    "    fighter_career_stats = fighter_soup.find('div', class_='b-list__info-box-left')\n",
    "    if fighter_career_stats:\n",
    "        career_stats = fighter_career_stats.find_all('li', class_='b-list__box-list-item')\n",
    "        for stat in career_stats:\n",
    "            label_element = stat.find('i', class_='b-list__box-item-title')\n",
    "            value = stat.get_text(strip=True).replace(label_element.get_text(strip=True), '').strip()\n",
    "            label = label_element.get_text(strip=True).rstrip(':')\n",
    "\n",
    "            if label in ['Str. Acc.', 'Str. Def', 'TD Acc.', 'TD Def.']:\n",
    "                new_label = f\"{label} (%)\"\n",
    "                converted_value = convert_percentage(value)\n",
    "                fighter_data[new_label] = converted_value\n",
    "            else:\n",
    "                fighter_data[label] = value\n",
    "\n",
    "    cols_to_strip_percent = ['Str. Acc. (%)', 'Str. Def (%)', 'TD Acc. (%)', 'TD Def. (%)']\n",
    "    fighter_df = pd.DataFrame([fighter_data])\n",
    "    fighter_df[cols_to_strip_percent] = fighter_df[cols_to_strip_percent].replace('%', '', regex=True)\n",
    "    \n",
    "    \n",
    "    fighter_df['DOB:'] = pd.to_datetime(fighter_df['DOB:'], format='%b %d, %Y')\n",
    "    today = datetime.datetime.today()\n",
    "    fighter_df['Age'] = (today - fighter_df['DOB:']).apply(lambda x: x.days // 365)\n",
    "    fighter_df.drop(columns=['DOB:'], inplace=True)\n",
    "\n",
    "    fighter_df.drop('', axis=1, inplace=True)\n",
    "    return fighter_df\n",
    "\n",
    "\n",
    "def get_opponent_stats(fighter_url):\n",
    "    opponent_urls = []\n",
    "\n",
    "    fighter_page = requests.get(fighter_url)\n",
    "    fighter_soup = BeautifulSoup(fighter_page.content, 'html.parser')\n",
    "\n",
    "    recent_fights_table = fighter_soup.find('table')\n",
    "    recent_fights_rows = recent_fights_table.find_all('tr')\n",
    "\n",
    "    for row in recent_fights_rows:\n",
    "        fighter_column = row.find('td', class_='b-fight-details__table-col l-page_align_left')\n",
    "        \n",
    "        if fighter_column:\n",
    "            fighter_links = fighter_column.find_all('a', class_='b-link b-link_style_black')\n",
    "            if len(fighter_links) >= 2:\n",
    "                opponent_url = fighter_links[1]['href']\n",
    "                opponent_urls.append(opponent_url)\n",
    "    \n",
    "    opponent_stats_dfs = []\n",
    "    for opponent_url in opponent_urls:\n",
    "        opponent_stats_df = fighter_stats(opponent_url)\n",
    "        opponent_stats_dfs.append(opponent_stats_df)\n",
    "    \n",
    "    combined_opponent_stats = pd.concat(opponent_stats_dfs, ignore_index=True)\n",
    "    combined_opponent_stats.columns = [\"Opponent \" + col for col in combined_opponent_stats.columns]\n",
    "    return combined_opponent_stats\n",
    "\n",
    "\n",
    "def scrape_fight_data(fight_url):   \n",
    "    fight_page = requests.get(fight_url)\n",
    "    fight_soup = BeautifulSoup(fight_page.content, 'html.parser')\n",
    "\n",
    "    data = []\n",
    "    fight_table = fight_soup.find('tbody', class_='b-fight-details__table-body')\n",
    "\n",
    "    fighter_divs = fight_soup.find_all('div', class_='b-fight-details__person')\n",
    "    outcomes = [outcome_tag.get_text(strip=True) if (outcome_tag := fighter_div.find('i', class_='b-fight-details__person-status')) else None for fighter_div in fighter_divs]\n",
    "\n",
    "    for row in fight_table.find_all('tr', class_='b-fight-details__table-row'):\n",
    "        fighter_names = row.find_all('a', class_='b-link_style_black')\n",
    "        fighters = [name.get_text(strip=True) for name in fighter_names]\n",
    "\n",
    "        kd = [col.get_text(strip=True) for col in row.find_all('td')[1].find_all('p')]\n",
    "        sig_str = [col.get_text(strip=True) for col in row.find_all('td')[2].find_all('p')]\n",
    "        sig_str_percent = [col.get_text(strip=True) for col in row.find_all('td')[3].find_all('p')]\n",
    "        total_str = [col.get_text(strip=True) for col in row.find_all('td')[4].find_all('p')]\n",
    "        td = [col.get_text(strip=True) for col in row.find_all('td')[5].find_all('p')]\n",
    "        td_percent = [col.get_text(strip=True) for col in row.find_all('td')[6].find_all('p')]\n",
    "        sub_att = [col.get_text(strip=True) for col in row.find_all('td')[7].find_all('p')]\n",
    "        rev = [col.get_text(strip=True) for col in row.find_all('td')[8].find_all('p')]\n",
    "        ctrl = [col.get_text(strip=True) for col in row.find_all('td')[9].find_all('p')]\n",
    "\n",
    "        for i in range(len(fighters)):\n",
    "            fight_info = {\n",
    "                'Fighter': fighters[i],\n",
    "                'KD': kd[i],\n",
    "                'Sig. str.': sig_str[i],\n",
    "                'Sig. str. %': sig_str_percent[i],\n",
    "                'Total str.': total_str[i],\n",
    "                'Td': td[i],\n",
    "                'Td %': td_percent[i],\n",
    "                'Sub. att': sub_att[i],\n",
    "                'Rev.': rev[i],\n",
    "                'Ctrl': ctrl[i],\n",
    "                'Fight URL': fight_url,\n",
    "                'Outcome': outcomes[i] \n",
    "            }\n",
    "            data.append(fight_info)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    new_data = []\n",
    "    new_columns = [\n",
    "        'Fighter', 'Opponent', 'KD', 'Opponent KD', 'Sig. str.', 'Opponent Sig. str.',\n",
    "        'Sig. str. %', 'Opponent Sig. str. %', 'Total str.', 'Opponent Total str.',\n",
    "        'Td', 'Opponent Td', 'Td %', 'Opponent Td %', 'Sub. att', 'Opponent Sub. att',\n",
    "        'Rev.', 'Opponent Rev.', 'Ctrl', 'Opponent Ctrl', 'Outcome'\n",
    "    ]\n",
    "\n",
    "    for i in range(0, len(df), 2):\n",
    "        fighter_row = df.iloc[i]\n",
    "        opponent_row = df.iloc[i + 1]\n",
    "\n",
    "        new_row = [\n",
    "            fighter_row['Fighter'], opponent_row['Fighter'],\n",
    "            fighter_row['KD'], opponent_row['KD'],\n",
    "            fighter_row['Sig. str.'], opponent_row['Sig. str.'],\n",
    "            fighter_row['Sig. str. %'], opponent_row['Sig. str. %'],\n",
    "            fighter_row['Total str.'], opponent_row['Total str.'],\n",
    "            fighter_row['Td'], opponent_row['Td'],\n",
    "            fighter_row['Td %'], opponent_row['Td %'],\n",
    "            fighter_row['Sub. att'], opponent_row['Sub. att'],\n",
    "            fighter_row['Rev.'], opponent_row['Rev.'],\n",
    "            fighter_row['Ctrl'], opponent_row['Ctrl'],\n",
    "            fighter_row['Outcome']\n",
    "        ]\n",
    "\n",
    "        new_data.append(new_row)\n",
    "\n",
    "    fight_df = pd.DataFrame(new_data, columns=new_columns)\n",
    "\n",
    "    fight_df.replace('---', None, inplace=True)\n",
    "\n",
    "\n",
    "    try:\n",
    "        fight_df['Sig. str. %'] = fight_df['Sig. str. %'].apply(convert_percentage)\n",
    "        fight_df['Opponent Sig. str. %'] = fight_df['Opponent Sig. str. %'].apply(convert_percentage)\n",
    "        fight_df['Td %'] = fight_df['Td %'].apply(convert_percentage)\n",
    "        fight_df['Opponent Td %'] = fight_df['Opponent Td %'].apply(convert_percentage)\n",
    "    except AttributeError:\n",
    "        pass  \n",
    "\n",
    "\n",
    "    fight_df[['Sig. Landed', 'Sig. Attempted']] = fight_df['Sig. str.'].str.split(' of ', expand=True)\n",
    "    fight_df['Sig. Landed'] = fight_df['Sig. Landed'].astype(int)\n",
    "    fight_df['Sig. Attempted'] = fight_df['Sig. Attempted'].astype(int)\n",
    "\n",
    "    fight_df[[\"Opponent Sig. Landed\", \"Opponent Sig. Attempted\"]] = fight_df[\"Opponent Sig. str.\"].str.split(' of ', expand=True)\n",
    "    fight_df[\"Opponent Sig. Landed\"] = fight_df[\"Opponent Sig. Landed\"].astype(int)\n",
    "    fight_df[\"Opponent Sig. Attempted\"] = fight_df[\"Opponent Sig. Attempted\"].astype(int)\n",
    "\n",
    "    fight_df[['Total Landed', 'Total Attempted']] = fight_df['Total str.'].str.split(' of ', expand=True)\n",
    "    fight_df['Total Landed'] = fight_df['Total Landed'].astype(int)\n",
    "    fight_df['Total Attempted'] = fight_df['Total Attempted'].astype(int)\n",
    "\n",
    "    fight_df[['Opponent Total Landed', 'Opponent Total Attempted']] = fight_df['Opponent Total str.'].str.split(' of ', expand=True)\n",
    "    fight_df['Opponent Total Landed'] = fight_df['Opponent Total Landed'].astype(int)\n",
    "    fight_df['Opponent Total Attempted'] = fight_df['Opponent Total Attempted'].astype(int)\n",
    "\n",
    "    fight_df[['Td Landed', 'Td Attempted']] = fight_df['Td'].str.split(' of ', expand=True)\n",
    "    fight_df['Td Landed'] = fight_df['Td Landed'].astype(int)\n",
    "    fight_df['Td Attempted'] = fight_df['Td Attempted'].astype(int)\n",
    "\n",
    "    fight_df[['Opponent Td Landed', 'Opponent Td Attempted']] = fight_df['Opponent Td'].str.split(' of ', expand=True)\n",
    "    fight_df['Opponent Td Landed'] = fight_df['Opponent Td Landed'].astype(int)\n",
    "    fight_df['Opponent Td Attempted'] = fight_df['Opponent Td Attempted'].astype(int)\n",
    "\n",
    "    fight_df.drop(['Sig. str.', \"Opponent Sig. str.\", 'Total str.', 'Opponent Total str.', 'Td', 'Opponent Td'], axis=1, inplace=True)\n",
    "\n",
    "    return fight_df\n",
    "\n",
    "\n",
    "#CREATE FUNCTION TO SCRAPE PAST FIGHT RESULST FROM A FIGHTER'S URL PAGE\n",
    "def past_fights(fighter_url):\n",
    "    fighter_page = requests.get(fighter_url)\n",
    "    fighter_soup = BeautifulSoup(fighter_page.content, 'html.parser')\n",
    "\n",
    "    # Get searched fighter's name\n",
    "    fighter_name = fighter_soup.find('span', class_='b-content__title-highlight').get_text(strip=True)\n",
    "    \n",
    "    #Create DF from all previous fights from searched fighter\n",
    "    fight_urls = get_fighter_fight_urls(fighter_url)\n",
    "    all_fight_dfs = []\n",
    "    for fight_url in fight_urls:\n",
    "        fight_df = scrape_fight_data(fight_url)\n",
    "        all_fight_dfs.append(fight_df)\n",
    "\n",
    "    combined_df = pd.concat(all_fight_dfs, ignore_index=True)\n",
    "\n",
    "    #Add the fight information to DF\n",
    "    fight_table = fighter_soup.find('tbody', class_='b-fight-details__table-body')\n",
    "\n",
    "    each_fight_details = fight_table.find_all('tr')\n",
    "\n",
    "    for idx, fight in enumerate(each_fight_details[1:]):\n",
    "        event_info_elements = fight.find_all('td', class_='b-fight-details__table-col l-page_align_left')\n",
    "        round_time_elements = fight.find_all('td', class_='b-fight-details__table-col')\n",
    "\n",
    "        event_name = event_info_elements[1].find_all('p')[0].text.strip()\n",
    "        event_date = event_info_elements[1].find_all('p')[1].text.strip()\n",
    "\n",
    "        try:\n",
    "            method_of_victory = event_info_elements[2].find('p').text.strip()\n",
    "        except AttributeError:\n",
    "            method_of_victory = None\n",
    "        \n",
    "        rounds_element = round_time_elements[-2].find('p')\n",
    "        if rounds_element:\n",
    "            rounds = rounds_element.text.strip()\n",
    "        else:\n",
    "            rounds = None\n",
    "\n",
    "        time_element = round_time_elements[-1].find('p')\n",
    "        if time_element:\n",
    "            time = time_element.text.strip()\n",
    "        else:\n",
    "            time = None\n",
    "        ''' \n",
    "        rounds = round_time_elements[-2].find('p').text.strip()\n",
    "        time = round_time_elements[-1].find('p').text.strip()'''\n",
    "\n",
    "        combined_df.at[idx, 'Event Name'] = event_name\n",
    "        combined_df.at[idx, 'Event Date'] = event_date\n",
    "        combined_df.at[idx, 'Method of Victory'] = method_of_victory\n",
    "        combined_df.at[idx, 'Rounds'] = rounds\n",
    "        combined_df.at[idx, 'Time'] = time\n",
    "\n",
    "    # Flip the data from Opponent to Fighter if the searched fighter is Opponent\n",
    "    for index, row in combined_df.iterrows():\n",
    "        if row['Opponent'] == fighter_name:\n",
    "            combined_df.at[index, 'Fighter'] = row['Opponent']\n",
    "            combined_df.at[index, 'Opponent'] = row['Fighter']\n",
    "\n",
    "            combined_df.at[index, 'KD'] = row['Opponent KD']\n",
    "            combined_df.at[index, 'Opponent KD'] = row['KD']\n",
    "\n",
    "            combined_df.at[index, 'Sig. str. %'] = row['Opponent Sig. str. %']\n",
    "            combined_df.at[index, 'Opponent Sig. str. %'] = row['Sig. str. %']\n",
    "\n",
    "            combined_df.at[index, 'Td %'] = row['Opponent Td %']\n",
    "            combined_df.at[index, 'Opponent Td %'] = row['Td %']\n",
    "\n",
    "            combined_df.at[index, 'Sub. att'] = row['Opponent Sub. att']\n",
    "            combined_df.at[index, 'Opponent Sub. att'] = row['Sub. att']\n",
    "\n",
    "            combined_df.at[index, 'Rev.'] = row['Opponent Rev.']\n",
    "            combined_df.at[index, 'Opponent Rev.'] = row['Rev.']\n",
    "\n",
    "            combined_df.at[index, 'Ctrl'] = row['Opponent Ctrl']\n",
    "            combined_df.at[index, 'Opponent Ctrl'] = row['Ctrl']\n",
    "\n",
    "            if row['Outcome'] == 'W':\n",
    "                combined_df.at[index, 'Outcome'] = 'L'\n",
    "            elif row['Outcome'] == 'L':\n",
    "                combined_df.at[index, 'Outcome'] = 'W'\n",
    "\n",
    "            combined_df.at[index, 'Sig. Landed'] = row['Opponent Sig. Landed']\n",
    "            combined_df.at[index, 'Opponent Sig. Landed'] = row['Sig. Landed']     \n",
    "\n",
    "            combined_df.at[index, 'Sig. Attempted'] = row['Opponent Sig. Attempted']\n",
    "            combined_df.at[index, 'Opponent Sig. Attempted'] = row['Sig. Attempted']  \n",
    "\n",
    "            combined_df.at[index, 'Total Landed'] = row['Opponent Total Landed']\n",
    "            combined_df.at[index, 'Opponent Total Landed'] = row['Total Landed']   \n",
    "\n",
    "            combined_df.at[index, 'Total Attempted'] = row['Opponent Total Attempted']\n",
    "            combined_df.at[index, 'Opponent Total Attempted'] = row['Total Attempted']     \n",
    "\n",
    "            combined_df.at[index, 'Td Landed'] = row['Opponent Td Landed']\n",
    "            combined_df.at[index, 'Opponent Td Landed'] = row['Td Landed']\n",
    "\n",
    "            combined_df.at[index, 'Td Attempted'] = row['Opponent Td Attempted']\n",
    "            combined_df.at[index, 'Opponent Td Attempted'] = row['Td Attempted']           \n",
    "    \n",
    "    #ADD OHTER INTERESTING DATA TO BE USED IN ANALYSIS\n",
    "\n",
    "    #Add current streak\n",
    "    current_streak = []\n",
    "    streak_type = []\n",
    "\n",
    "    win_streak = 0\n",
    "    loss_streak = 0\n",
    "\n",
    "    for index, row in combined_df.iterrows():\n",
    "        outcome = row['Outcome']\n",
    "\n",
    "        if outcome == 'W':\n",
    "            win_streak += 1\n",
    "            loss_streak = 0\n",
    "        elif outcome == 'L':\n",
    "            loss_streak += 1\n",
    "            win_streak = 0\n",
    "        else:\n",
    "            win_streak = 0\n",
    "            loss_streak = 0\n",
    "\n",
    "        if win_streak > 0:\n",
    "            current_streak.append(win_streak)\n",
    "            streak_type.append('Win')\n",
    "        elif loss_streak > 0:\n",
    "            current_streak.append(loss_streak)\n",
    "            streak_type.append('Loss')\n",
    "        else:\n",
    "            current_streak.append(0)\n",
    "            streak_type.append('None')\n",
    "\n",
    "\n",
    "    combined_df['Current Streak'] = current_streak\n",
    "    combined_df['Streak Type'] = streak_type\n",
    "\n",
    "    # Add how long between each fight for analysis\n",
    "    \n",
    "    combined_df['Event Date'] = pd.to_datetime(combined_df['Event Date'])\n",
    "\n",
    "    combined_df = combined_df.sort_values(by='Event Date', ascending=True)\n",
    "\n",
    "    combined_df['Days since last fight'] = (combined_df['Event Date'] - combined_df['Event Date'].shift(1)).dt.days\n",
    "\n",
    "    combined_df['Days since last fight'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "#CREATE A FUNCTION TO CREATE A DF FROM FIGHTER_URL\n",
    "def full_past_fights(fighter_url):\n",
    "    past_fights_df = past_fights(fighter_url)  \n",
    "\n",
    "    opponent_stats_df = get_opponent_stats(fighter_url)\n",
    "\n",
    "    combined_df = pd.concat([past_fights_df, opponent_stats_df], axis=1)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "def convert_ctrl_to_seconds(ctrl_time):\n",
    "    if pd.isna(ctrl_time):\n",
    "        return np.nan\n",
    "    minutes, seconds = map(int, ctrl_time.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "def preprocessing_data(fighter_url):\n",
    "    fighter_df = full_past_fights(fighter_url)\n",
    "\n",
    "    fighter_df.drop(['Fighter', 'Opponent', 'Event Name', 'Event Date', 'Time','Method of Victory', \"Opponent STANCE:\", \"Streak Type\"], axis=1, inplace=True)\n",
    "\n",
    "    fighter_df['Ctrl'] = fighter_df['Ctrl'].replace('--', np.nan)\n",
    "    fighter_df['Opponent Ctrl'] = fighter_df['Opponent Ctrl'].replace('--', np.nan)\n",
    "\n",
    "    try:\n",
    "        fighter_df['Ctrl (in seconds)'] = fighter_df['Ctrl'].apply(convert_ctrl_to_seconds)\n",
    "        fighter_df['Opponent Ctrl (in seconds)'] = fighter_df['Opponent Ctrl'].apply(convert_ctrl_to_seconds)\n",
    "        fighter_df.drop(['Ctrl', 'Opponent Ctrl'], axis=1, inplace=True)\n",
    "    except ValueError:\n",
    "        fighter_df['Ctrl (in seconds)'] = np.nan\n",
    "        fighter_df['Opponent Ctrl (in seconds)'] = np.nan\n",
    "    \n",
    "    return fighter_df\n",
    "\n",
    "def clean_df(fighter_url):\n",
    "    clean_fighter_df = preprocessing_data(fighter_url)\n",
    "    clean_fighter_df['Outcome'] = clean_fighter_df['Outcome'].apply(lambda x: 1 if x == 'W' else (0 if x == 'L' else np.nan))\n",
    "\n",
    "    no_na_df = clean_fighter_df.dropna()\n",
    "\n",
    "    return no_na_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_omalley_df = clean_df('http://www.ufcstats.com/fighter-details/b50a426a33da0012')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_omalley_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sterling_df = clean_df('http://www.ufcstats.com/fighter-details/cb696ebfb6598724')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_sterling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omalley_df = load_omalley_df\n",
    "sterling_df = load_sterling_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omalley_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "historical_fight_data = pd.read_csv(\"C:/Users/Bootcamp/Desktop/prediction_app/model/all_weights.csv\")\n",
    "historical_fight_data['Outcome'] = historical_fight_data['Outcome'].apply(lambda x: 1 if x == 'W' else (0 if x == 'L' else np.nan))\n",
    "\n",
    "historical_fight_data.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_fight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = historical_fight_data.columns[:20].tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names2 = historical_fight_data.columns[20:].tolist()\n",
    "print(column_names2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have preprocessed your data and defined selected_features and historical_fight_data\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    historical_fight_data.drop(columns=['Outcome']),\n",
    "    historical_fight_data[\"Outcome\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build and train a Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Evaluate the model on the validation set\n",
    "val_predictions = rf_model.predict(X_val)\n",
    "\n",
    "# You can use classification metrics to assess the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, val_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report for more details\n",
    "report = classification_report(y_val, val_predictions)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns from omalley_df and sterling_df\n",
    "relevant_columns = historical_fight_data.columns.tolist()\n",
    "omalley_stats = omalley_df[relevant_columns].values.reshape(1, -1)\n",
    "sterling_stats = sterling_df[relevant_columns].values.reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 80 features, but RandomForestClassifier is expecting 39 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m omalley_prediction \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39;49mpredict(omalley_stats)\n\u001b[0;32m      2\u001b[0m sterling_prediction \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(sterling_stats)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Interpret the predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 80 features, but RandomForestClassifier is expecting 39 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "omalley_prediction = rf_model.predict(omalley_stats)\n",
    "sterling_prediction = rf_model.predict(sterling_stats)\n",
    "\n",
    "# Interpret the predictions\n",
    "if omalley_prediction[0] == 1:\n",
    "    print(\"Sean O'Malley is predicted to win with Random Forest.\")\n",
    "else:\n",
    "    print(\"Sean O'Malley is predicted to lose with Random Forest.\")\n",
    "\n",
    "if sterling_prediction[0] == 1:\n",
    "    print(\"Aljamain Sterling is predicted to win with Random Forest.\")\n",
    "else:\n",
    "    print(\"Aljamain Sterling is predicted to lose with Random Forest.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(omalley_df.columns.tolist() == sterling_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(omalley_df.columns.tolist() == historical_fight_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 80)\n",
      "(1, 360)\n"
     ]
    }
   ],
   "source": [
    "print(omalley_stats.shape)\n",
    "print(sterling_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 80 features, but RandomForestClassifier is expecting 39 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[173], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m omalley_stats \u001b[39m=\u001b[39m omalley_df[relevant_columns]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m sterling_stats \u001b[39m=\u001b[39m sterling_df[relevant_columns]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m omalley_prediction \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39;49mpredict(omalley_stats)\n\u001b[0;32m      8\u001b[0m sterling_prediction \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(sterling_stats)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Interpret the predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Bootcamp\\Desktop\\prediction_app\\venv\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 80 features, but RandomForestClassifier is expecting 39 features as input."
     ]
    }
   ],
   "source": [
    "# Check if columns match\n",
    "if omalley_df.columns.tolist() == historical_fight_data.columns.tolist() and sterling_df.columns.tolist() == historical_fight_data.columns.tolist():\n",
    "    relevant_columns = historical_fight_data.columns.tolist()\n",
    "    omalley_stats = omalley_df[relevant_columns].values.reshape(1, -1)\n",
    "    sterling_stats = sterling_df[relevant_columns].values.reshape(1, -1)\n",
    "\n",
    "    omalley_prediction = rf_model.predict(omalley_stats)\n",
    "    sterling_prediction = rf_model.predict(sterling_stats)\n",
    "\n",
    "    # Interpret the predictions\n",
    "    if omalley_prediction[0] == 1:\n",
    "        print(\"Sean O'Malley is predicted to win with Random Forest.\")\n",
    "    else:\n",
    "        print(\"Sean O'Malley is predicted to lose with Random Forest.\")\n",
    "\n",
    "    if sterling_prediction[0] == 1:\n",
    "        print(\"Aljamain Sterling is predicted to win with Random Forest.\")\n",
    "    else:\n",
    "        print(\"Aljamain Sterling is predicted to lose with Random Forest.\")\n",
    "else:\n",
    "    print(\"Columns in omalley_df and sterling_df do not match historical_fight_data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omalley_df shape: (2, 40)\n",
      "sterling_df shape: (9, 40)\n",
      "historical_fight_data shape: (377, 40)\n"
     ]
    }
   ],
   "source": [
    "print(\"omalley_df shape:\", omalley_df.shape)\n",
    "print(\"sterling_df shape:\", sterling_df.shape)\n",
    "print(\"historical_fight_data shape:\", historical_fight_data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
